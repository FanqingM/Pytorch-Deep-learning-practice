{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5afca213e3fd4a905a1ee04cf013c4a2a70ed6bf52820ba3c074a5841fff5c71"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 2.4867076873779297\n1 2.3713269233703613\n2 2.2966604232788086\n3 2.2477617263793945\n4 2.2139859199523926\n5 2.1886723041534424\n6 2.167980670928955\n7 2.1498048305511475\n8 2.1330246925354004\n9 2.117053985595703\n10 2.1015896797180176\n11 2.086474895477295\n12 2.071629047393799\n13 2.057009696960449\n14 2.042593479156494\n15 2.0283689498901367\n16 2.0143275260925293\n17 2.000464916229248\n18 1.9867770671844482\n19 1.9732615947723389\n20 1.9599151611328125\n21 1.9467357397079468\n22 1.9337204694747925\n23 1.920867681503296\n24 1.9081752300262451\n25 1.895640254020691\n26 1.88326096534729\n27 1.8710349798202515\n28 1.8589603900909424\n29 1.8470351696014404\n30 1.8352570533752441\n31 1.8236234188079834\n32 1.8121330738067627\n33 1.8007839918136597\n34 1.789573311805725\n35 1.7784998416900635\n36 1.7675611972808838\n37 1.7567555904388428\n38 1.7460813522338867\n39 1.7355358600616455\n40 1.7251181602478027\n41 1.7148257493972778\n42 1.7046570777893066\n43 1.6946101188659668\n44 1.6846833229064941\n45 1.6748751401901245\n46 1.6651830673217773\n47 1.6556062698364258\n48 1.646142601966858\n49 1.6367905139923096\n50 1.6275482177734375\n51 1.6184141635894775\n52 1.609386920928955\n53 1.6004648208618164\n54 1.5916463136672974\n55 1.5829298496246338\n56 1.5743138790130615\n57 1.565796971321106\n58 1.557377815246582\n59 1.5490548610687256\n60 1.5408265590667725\n61 1.5326913595199585\n62 1.5246484279632568\n63 1.5166959762573242\n64 1.5088329315185547\n65 1.5010578632354736\n66 1.493369221687317\n67 1.4857666492462158\n68 1.4782476425170898\n69 1.4708117246627808\n70 1.4634575843811035\n71 1.456183910369873\n72 1.4489896297454834\n73 1.441873550415039\n74 1.434834361076355\n75 1.4278712272644043\n76 1.420982837677002\n77 1.414168119430542\n78 1.4074259996414185\n79 1.4007556438446045\n80 1.3941559791564941\n81 1.3876255750656128\n82 1.3811640739440918\n83 1.3747698068618774\n84 1.3684422969818115\n85 1.362180471420288\n86 1.355983018875122\n87 1.3498494625091553\n88 1.3437788486480713\n89 1.3377702236175537\n90 1.3318226337432861\n91 1.3259353637695312\n92 1.3201074600219727\n93 1.314338207244873\n94 1.3086262941360474\n95 1.302971363067627\n96 1.2973726987838745\n97 1.291829228401184\n98 1.286340355873108\n99 1.2809052467346191\nw =  0.8341392278671265\nb =  -2.0372259616851807\ny_pred =  tensor([[0.7857]])\n"
     ]
    }
   ],
   "source": [
    "# 第六讲 logistic回归\n",
    "import torch\n",
    "# import torch.nn.functional as F\n",
    " \n",
    "# prepare dataset\n",
    "x_data = torch.Tensor([[1.0], [2.0], [3.0]]) # 3✖️1的tensor\n",
    "y_data = torch.Tensor([[0], [0], [1]])     # 同上\n",
    " \n",
    "#design model using class\n",
    "class LogisticRegressionModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1,1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        # y_pred = F.sigmoid(self.linear(x))\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "model = LogisticRegressionModel()\n",
    " \n",
    "# construct loss and optimizer\n",
    "# 这里所有样本就是一个batch进去训练的\n",
    "# 默认情况下，loss会基于element平均，如果size_average=False的话，loss会被累加。当我们采用mini-batch方法训练时，有时可能最后一个batch的batchSize与之前不一样就需要除一下。\n",
    "criterion = torch.nn.BCELoss(size_average = False) \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.07)\n",
    " \n",
    "# training cycle forward, backward, update\n",
    "for epoch in range(100):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.item())\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    " \n",
    "print('w = ', model.linear.weight.item())\n",
    "print('b = ', model.linear.bias.item())\n",
    " \n",
    "x_test = torch.Tensor([[4.0]])\n",
    "y_test = model(x_test)\n",
    "print('y_pred = ', y_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lecture7:处理多维输入\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# prepare dataset\n",
    "xy = np.loadtxt('diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = torch.from_numpy(xy[:, :-1]) # 第一个‘：’是指读取所有行，第二个‘：’是指从第一列开始，最后一列不要\n",
    "y_data = torch.from_numpy(xy[:, [-1]]) # [-1] 最后得到的是个矩阵\n",
    " \n",
    "# design model using class\n",
    " \n",
    " \n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(8, 6) # 输入数据x的特征是8维，x有8个特征\n",
    "        self.linear2 = torch.nn.Linear(6, 4)\n",
    "        self.linear3 = torch.nn.Linear(4, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid() # 将其看作是网络的一层，而不是简单的函数使用,这里不能用relu，因为会出现大雨1的，会跟下面用的BCEloss冲突的。\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.linear1(x))\n",
    "        x = self.sigmoid(self.linear2(x))\n",
    "        x = self.sigmoid(self.linear3(x)) # y hat\n",
    "        return x\n",
    " \n",
    " \n",
    "model = Model()\n",
    " \n",
    "# construct loss and optimizer\n",
    "# criterion = torch.nn.BCELoss(size_average = True)\n",
    "criterion = torch.nn.BCELoss(reduction='mean')  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
    " \n",
    "epoch_list = []\n",
    "loss_list = []\n",
    "# training cycle forward, backward, update\n",
    "for epoch in range(300):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.item())\n",
    "    epoch_list.append(epoch)\n",
    "    loss_list.append(loss.item())\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    " \n",
    "    optimizer.step()\n",
    " \n",
    " \n",
    "plt.plot(epoch_list, loss_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.294118"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "xy = np.loadtxt('diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "xy\n",
    "xy[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "input data.shape torch.Size([759, 8])\n",
      "loss =  0.6582362651824951 acc =  0.3465085638998682\n",
      "loss =  0.6515761613845825 acc =  0.3465085638998682\n",
      "loss =  0.6483912467956543 acc =  0.3465085638998682\n",
      "loss =  0.6468424201011658 acc =  0.6534914361001317\n",
      "loss =  0.6460798978805542 acc =  0.6534914361001317\n",
      "loss =  0.6457011699676514 acc =  0.6534914361001317\n",
      "loss =  0.6455118656158447 acc =  0.6534914361001317\n",
      "loss =  0.645416796207428 acc =  0.6534914361001317\n",
      "loss =  0.6453688740730286 acc =  0.6534914361001317\n",
      "loss =  0.6453445553779602 acc =  0.6534914361001317\n",
      "loss =  0.6453322172164917 acc =  0.6534914361001317\n",
      "loss =  0.6453258395195007 acc =  0.6534914361001317\n",
      "loss =  0.6453225612640381 acc =  0.6534914361001317\n",
      "loss =  0.6453208327293396 acc =  0.6534914361001317\n",
      "loss =  0.6453198790550232 acc =  0.6534914361001317\n",
      "loss =  0.645319402217865 acc =  0.6534914361001317\n",
      "loss =  0.6453189849853516 acc =  0.6534914361001317\n",
      "loss =  0.6453187465667725 acc =  0.6534914361001317\n",
      "loss =  0.6453185081481934 acc =  0.6534914361001317\n",
      "loss =  0.645318329334259 acc =  0.6534914361001317\n",
      "loss =  0.6453182101249695 acc =  0.6534914361001317\n",
      "loss =  0.6453180313110352 acc =  0.6534914361001317\n",
      "loss =  0.6453179717063904 acc =  0.6534914361001317\n",
      "loss =  0.645317792892456 acc =  0.6534914361001317\n",
      "loss =  0.6453176140785217 acc =  0.6534914361001317\n",
      "loss =  0.6453174352645874 acc =  0.6534914361001317\n",
      "loss =  0.6453173160552979 acc =  0.6534914361001317\n",
      "loss =  0.6453171968460083 acc =  0.6534914361001317\n",
      "loss =  0.6453170776367188 acc =  0.6534914361001317\n",
      "loss =  0.6453168988227844 acc =  0.6534914361001317\n",
      "loss =  0.6453167200088501 acc =  0.6534914361001317\n",
      "loss =  0.6453166007995605 acc =  0.6534914361001317\n",
      "loss =  0.6453164219856262 acc =  0.6534914361001317\n",
      "loss =  0.6453163623809814 acc =  0.6534914361001317\n",
      "loss =  0.6453161835670471 acc =  0.6534914361001317\n",
      "loss =  0.6453160047531128 acc =  0.6534914361001317\n",
      "loss =  0.6453158855438232 acc =  0.6534914361001317\n",
      "loss =  0.6453157663345337 acc =  0.6534914361001317\n",
      "loss =  0.6453155875205994 acc =  0.6534914361001317\n",
      "loss =  0.6453155279159546 acc =  0.6534914361001317\n",
      "loss =  0.6453152894973755 acc =  0.6534914361001317\n",
      "loss =  0.6453152298927307 acc =  0.6534914361001317\n",
      "loss =  0.6453150510787964 acc =  0.6534914361001317\n",
      "loss =  0.6453149914741516 acc =  0.6534914361001317\n",
      "loss =  0.6453147530555725 acc =  0.6534914361001317\n",
      "loss =  0.645314633846283 acc =  0.6534914361001317\n",
      "loss =  0.6453144550323486 acc =  0.6534914361001317\n",
      "loss =  0.6453143954277039 acc =  0.6534914361001317\n",
      "loss =  0.6453142166137695 acc =  0.6534914361001317\n",
      "loss =  0.64531409740448 acc =  0.6534914361001317\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# prepare dataset\n",
    "xy = np.loadtxt('diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = torch.from_numpy(xy[:, :-1]) # 第一个‘：’是指读取所有行，第二个‘：’是指从第一列开始，最后一列不要\n",
    "print(\"input data.shape\", x_data.shape)\n",
    "y_data = torch.from_numpy(xy[:, [-1]]) # [-1] 最后得到的是个矩阵\n",
    " \n",
    "# print(x_data.shape)\n",
    "# design model using class\n",
    " \n",
    " \n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(8, 6)\n",
    "        self.linear2 = torch.nn.Linear(6, 4)\n",
    "        self.linear3 = torch.nn.Linear(4, 2)\n",
    "        self.linear4 = torch.nn.Linear(2, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.linear1(x))\n",
    "        x = self.sigmoid(self.linear2(x))\n",
    "        x = self.sigmoid(self.linear3(x)) # y hat\n",
    "        x = self.linear4(x)  # y hat\n",
    "        return x\n",
    " \n",
    " \n",
    "model = Model()\n",
    " \n",
    "# construct loss and optimizer\n",
    "# criterion = torch.nn.BCELoss(size_average = True)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    " \n",
    " \n",
    "# training cycle forward, backward, update\n",
    "for epoch in range(500):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    # print(epoch, loss.item())\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    " \n",
    "    if epoch%10 == 9:\n",
    "        y_pred_label = torch.where(y_pred>=0.5,torch.tensor([1.0]),torch.tensor([0.0]))\n",
    " \n",
    "        acc = torch.eq(y_pred_label, y_data).sum().item()/y_data.size(0)\n",
    "        print(\"loss = \",loss.item(), \"acc = \",acc)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}